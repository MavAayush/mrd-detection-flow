{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44009739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "import joblib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f65e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset parameters\n",
    "RANDOM_SEED = 42\n",
    "VALIDATE_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc64966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seeds to ensure reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rn.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc097d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient file paths\n",
    "patients = {\n",
    "    1: ['Data/organized_fcs_data1a.csv', 'Data/organized_fcs_data1b.csv', 'Data/organized_fcs_data1c.csv'],\n",
    "    2: ['Data/organized_fcs_data2a.csv', 'Data/organized_fcs_data2b.csv', 'Data/organized_fcs_data2c.csv'],\n",
    "    3: ['Data/organized_fcs_data3a.csv', 'Data/organized_fcs_data3b.csv', 'Data/organized_fcs_data3c.csv'],\n",
    "    4: ['Data/organized_fcs_data4a.csv', 'Data/organized_fcs_data4b.csv', 'Data/organized_fcs_data4c.csv'],\n",
    "    5: ['Data/organized_fcs_data5a.csv', 'Data/organized_fcs_data5b.csv', 'Data/organized_fcs_data5c.csv'],\n",
    "    6: ['Data/organized_fcs_data6a.csv', 'Data/organized_fcs_data6b.csv', 'Data/organized_fcs_data6c.csv'],\n",
    "    7: ['Data/organized_fcs_data7.csv'],\n",
    "    8: ['Data/organized_fcs_data8a.csv', 'Data/organized_fcs_data8b.csv', 'Data/organized_fcs_data8c.csv'],\n",
    "    9: ['Data/organized_fcs_data9a.csv', 'Data/organized_fcs_data9b.csv'],\n",
    "    10: ['Data/organized_fcs_data10a.csv', 'Data/organized_fcs_data10b.csv', 'Data/organized_fcs_data10c.csv'],\n",
    "    11: ['Data/organized_fcs_data11.csv'],\n",
    "    12: ['Data/organized_fcs_data12a.csv', 'Data/organized_fcs_data12b.csv', 'Data/organized_fcs_data12c.csv']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03557d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dfs = []\n",
    "testing_dfs = []\n",
    "\n",
    "first_six_ids = [1, 2, 3, 4, 5, 6]\n",
    "training_ids = [1,2,3,4,6]     #leaving out patient no. 5 for validation\n",
    "\n",
    "for patient_id, file_paths in patients.items():\n",
    "    patient_data = pd.concat([pd.read_csv(file).drop(columns=['Time'], errors='ignore') for file in file_paths])\n",
    "    \n",
    "    if patient_id in training_ids:\n",
    "        training_dfs.append(patient_data)\n",
    "    if patient_id not in training_ids and patient_id in first_six_ids:\n",
    "        testing_dfs.append(patient_data)\n",
    "\n",
    "train_full = pd.concat(training_dfs, ignore_index=True)\n",
    "test_full = pd.concat(testing_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef8b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "print(training_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa1c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: 5\n",
      "Testing data samples: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data samples: {len(training_dfs)}\")\n",
    "print(f\"Testing data samples: {len(testing_dfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b705163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler', MinMaxScaler())])\n",
    "pipeline.fit(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c787067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and validation data with these parameters\n",
    "X_train_transformed = pipeline.transform(train_full)\n",
    "X_validate_transformed = pipeline.transform(test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2976b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_transformed.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d34255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff32da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45fb2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_transformed)\n",
    "val_dataset = CustomDataset(X_validate_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fcd84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355d76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super().__init__()\n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(4, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(4, latent_dim)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(16, input_dim),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        log_var = self.fc_log_var(encoded)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4dac61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarAutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=16, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc_log_var): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): Linear(in_features=16, out_features=14, bias=True)\n",
      "    (7): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder= VarAutoEncoder(input_dim=input_dim)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d0752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(reconstructed, original, mu, log_var, beta=1):\n",
    "    recon_loss = F.mse_loss(reconstructed, original, reduction='mean')\n",
    "    kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return recon_loss + beta * kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50aa4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, train_loader, val_loader, epochs=100, lr=0.001):\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"Training Variational Autoencoder for {epochs} epochs...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_data in train_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, mu, log_var = model(batch_data)\n",
    "            loss = vae_loss_function(reconstructed, batch_data, mu, log_var, beta=1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_data in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                reconstructed, mu, log_var = model(batch_data)\n",
    "                loss = vae_loss_function(reconstructed, batch_data, mu, log_var, beta=1)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1:3d}/{epochs} | Train: {avg_train_loss:.6f} | Val: {avg_val_loss:.6f} | Time: {epoch_time:.1f}s | Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "            model.load_state_dict(best_model)\n",
    "            break\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3cbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 866 parameters\n",
      "Training Variational Autoencoder for 100 epochs...\n",
      "--------------------------------------------------\n",
      "Epoch   1/100 | Train: 0.016839 | Val: 0.011610 | Time: 188.1s | Patience: 0/15\n",
      "Epoch   2/100 | Train: 0.016783 | Val: 0.011645 | Time: 126.4s | Patience: 1/15\n",
      "Epoch   3/100 | Train: 0.016781 | Val: 0.011696 | Time: 115.8s | Patience: 2/15\n",
      "Epoch   4/100 | Train: 0.016781 | Val: 0.011693 | Time: 115.9s | Patience: 3/15\n",
      "Epoch   5/100 | Train: 0.016780 | Val: 0.011732 | Time: 124.5s | Patience: 4/15\n",
      "Epoch   6/100 | Train: 0.016780 | Val: 0.011641 | Time: 127.1s | Patience: 5/15\n",
      "Epoch   7/100 | Train: 0.016780 | Val: 0.011589 | Time: 126.1s | Patience: 0/15\n",
      "Epoch   8/100 | Train: 0.016780 | Val: 0.011655 | Time: 115.6s | Patience: 1/15\n",
      "Epoch   9/100 | Train: 0.016780 | Val: 0.011593 | Time: 114.4s | Patience: 2/15\n",
      "Epoch  10/100 | Train: 0.016780 | Val: 0.011723 | Time: 127.6s | Patience: 3/15\n",
      "Epoch  11/100 | Train: 0.016780 | Val: 0.011617 | Time: 116.5s | Patience: 4/15\n",
      "Epoch  12/100 | Train: 0.016780 | Val: 0.011670 | Time: 107.5s | Patience: 5/15\n",
      "Epoch  13/100 | Train: 0.016780 | Val: 0.011661 | Time: 111.4s | Patience: 6/15\n",
      "Epoch  14/100 | Train: 0.016780 | Val: 0.011701 | Time: 103.2s | Patience: 7/15\n",
      "Epoch  15/100 | Train: 0.016780 | Val: 0.011717 | Time: 105.2s | Patience: 8/15\n",
      "Epoch  16/100 | Train: 0.016780 | Val: 0.011720 | Time: 104.6s | Patience: 9/15\n",
      "Epoch  17/100 | Train: 0.016780 | Val: 0.011680 | Time: 102.7s | Patience: 10/15\n",
      "Epoch  18/100 | Train: 0.016780 | Val: 0.011639 | Time: 103.2s | Patience: 11/15\n",
      "Epoch  19/100 | Train: 0.016780 | Val: 0.011719 | Time: 104.0s | Patience: 12/15\n",
      "Epoch  20/100 | Train: 0.016780 | Val: 0.011730 | Time: 103.7s | Patience: 13/15\n",
      "Epoch  21/100 | Train: 0.016780 | Val: 0.011775 | Time: 104.7s | Patience: 14/15\n",
      "Epoch  22/100 | Train: 0.016780 | Val: 0.011699 | Time: 103.6s | Patience: 15/15\n",
      "\n",
      "Early stopping at epoch 22\n",
      "Best validation loss: 0.011589\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    vae = autoencoder\n",
    "    print(f\"Model created with {sum(p.numel() for p in vae.parameters())} parameters\")\n",
    "    trained_model, train_history, val_history = train_autoencoder(\n",
    "        model=vae,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=0.001\n",
    "    ) \n",
    "    return trained_model, train_history, val_history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_model, train_losses, val_losses = run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54d09a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Only the model weights\n",
    "torch.save(trained_model.state_dict(), 'vae_2dim_b1_LOPO.pth')\n",
    "\n",
    "# Loading the model weights\n",
    "# autoencoder = VarAutoEncoder(input_dim=input_dim, latent_dim=2)\n",
    "# autoencoder.load_state_dict(torch.load(\"vae_2_LOPO.pth\"))\n",
    "# autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b966192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder_on_patient(patient_id, model, pipeline, patients_dict):\n",
    "    file_paths = patients_dict[patient_id]\n",
    "    patient_df = pd.concat([pd.read_csv(fp).drop(columns=['Time'], errors='ignore') for fp in file_paths], ignore_index=True)\n",
    "    patient_data_transformed = pipeline.transform(patient_df)\n",
    "    patient_tensor = torch.tensor(patient_data_transformed, dtype=torch.float32)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed, _, _ = model(patient_tensor)\n",
    "        reconstructed = reconstructed.numpy()\n",
    "    mse = np.mean((patient_data_transformed - reconstructed) ** 2, axis=1)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59ca3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00675749 0.00346686 0.00521256 ... 0.00258324 0.01831031 0.0059909 ]\n"
     ]
    }
   ],
   "source": [
    "pt1 = test_autoencoder_on_patient(5, trained_model, pipeline, patients)\n",
    "print(pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e96fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Predicted      Actual.     Reconstruction Error\n",
    "# 7    3.92%          3.28%         0.06049\n",
    "# 8    0.40%          1.2%          0.04856\n",
    "# 9    2.49%          9.3%          0.04527\n",
    "# 10   3.17%          2.17%         0.06527\n",
    "# 11   14.84%         14.6%         0.05654\n",
    "# 12   4.63%          4.2%          0.05897\n",
    "\n",
    "\n",
    "\n",
    "#Avg threshold = 0.055850000000000004\n",
    "\n",
    "\n",
    "# For Healthy patient 5 --> 0.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5871969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for top 4.2% reconstruction errors: 0.05897\n"
     ]
    }
   ],
   "source": [
    "percent_unhealthy = 4.2\n",
    "threshold_index = int((percent_unhealthy / 100) * len(pt1))\n",
    "threshold_value = np.sort(pt1)[-threshold_index]\n",
    "\n",
    "print(f\"Threshold for top {percent_unhealthy}% reconstruction errors: {threshold_value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97e71b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055850000000000004\n"
     ]
    }
   ],
   "source": [
    "print((0.06049+0.04856+0.04527+0.06527+0.05654+0.05897)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ae3f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23% of cells have reconstruction error > 0.055850000000000004\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.055850000000000004\n",
    "\n",
    "# Calculate percentage above threshold\n",
    "num_above = np.sum(pt1 > threshold)\n",
    "total = len(pt1)\n",
    "percent_above = (num_above / total) * 100\n",
    "\n",
    "print(f\"{percent_above:.2f}% of cells have reconstruction error > {threshold}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
